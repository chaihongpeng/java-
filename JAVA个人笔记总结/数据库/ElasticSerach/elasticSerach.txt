put请求必须具有幂等性
put /[索引名]创建索引


post没有幂等性
post /[索引]/[数据] 创建数据，这会随机生成id
	自己定义id
post/[索引]/[数据]/[主键id]

查询数据
get/[索引]/[数据]/[id]

查询索引下的所有数据
get/[索引]/[_search]

数据修改
put/[]/[]/

删除数据
delete /[索引]/[_doc]/[主键]

条件查询
get /[index]/[_search]?q=[主键]:[内容]







倒排索引的数据结构
TF关键词在每个doc文档中出现的次数,他的值越高相关度越高
IDF关键词在索引中的出现次数，越多相关度越低，证明这个关键词越没有代表性
每个doc的长度，越长相关度越低
关键词在当前doc中出现的次数


健康检查 -v是为了显示参数名，方便查看
GET /_cat/health?v
------------------------------------------------------------------------------------------------------------------
查询索引
GET /_cat/indices?v
------------------------------------------------------------------------------------------------------------------
创建索引
PUT /<索引名称>?pretty
------------------------------------------------------------------------------------------------------------------
删除索引
DELETE /<索引名称>/pretty
------------------------------------------------------------------------------------------------------------------
设置超时时间
GET /_search?timeout=<时间 1s、1ms>

查看分词器分割
GET /_analyze
{
	analyzer:<分词器，默认standard>
	text:<数据>
}

==================================================================================================================

插入数据和全量替换数据 
type在新的版本中几乎不再使用，一般统一使用_doc作为默认值

PUT /<索引名称>/<type表名>/<id>
{
	<字段名称>:<数据>
}
返回值
{
	_index:<索引名称>,
	_type:<type>,
	_id:<id>
	_version:<版本号>,
	result:<created执行类型>
	_shard:{
		total:<分片数>
		successful:<成功数>
		failed:<失败数>
	}
}
------------------------------------------------------------------------------------------------------------------
修改数据(部分替换数据)

POST /<索引>/<type>/<id>/_update
{
	doc:{
		<字段名称>:<数据>
	}
}
------------------------------------------------------------------------------------------------------------------
删除语句

DELETE /<索引名称>/<表type>/<id>

==================================================================================================================


查询数据
查询所有
query_string 语法
GET /<索引名称>/<type可以不加，不加就是在index下搜索>/_search?sort=<排序字段>:<asc/desc>&q=<字段名>:<查询词>&from=<分页起始位置>&size=<查询条数>&timeout=<1s查询超时时间>

------------------------------------------------------------------------------------------------------------------
query_DSL语法


GET /<index>/_search
{
	query:{
		(1)查询所有，相当于select *
		match_all:{}
		(2)短语搜索,整个name中要包含这一长串内容
		match_phrase:{
			<字段>:<数据>
		}
		(3)多字段匹配,一个搜索词可以同时在文章标题和内容中进行搜索
		multi_match:{
			query:<数据>
			fields:[
				<字段名>，
				<字段名>,
				....
			]
		}
		(4)关键词不分词查询，但是被索引字段根据数据类型决定是否分词
		term:{
			<字段名>:<数据>
		}
		(5)关键词查询不分词，多条件满足相当于sql的in
		terms:{
			<字段名>:[<数据>,<数据>]
		}
		(6)
		range:{
			<字段>:{
				gt:<范围大于>,
				lt:<范围小于>
				gte:<大于等于>
				lte:<小于等于>
			}
		}
	},
	//只返回所需要的字段，不影响查询条件相当于sql的select
	_source:[<字段名>,<字段名>],
	sort:[{
			<字段>:<desc/asc>
		}
	]
	from:<起始位，从0开始>,
	size:<查询条数>,
	hightlight:{
		fields:{
			<字段>:{}
		}
	}
	timeout:<超时时间 1s>
}

------------------------------------------------------------------------------------------------------------------
组合查询
GET /<index>/_search
{
	query:{
		bool:{
			(1)相当于and
			//查询结果必须同时满足一下条件
			must:[{term:{<字段名>:<数据>,<字段名>:<数据>}...}]
			(2)相当于or
			should:[]
			(3)筛选出符合条件的数据，默认不计算相关度，性能比query高，而且支持缓存
			filter:[],
			(4)不包含的条件
			must_not:[]
		},
		//如果bool中只有should，该数字表示should中至少要满足几条条件，默认为1，如果有must默认就是0
		mininum_should_match:<数字1,2>
	}
}

==================================================================================================================

deep paging问题
	当你的数据超过一万条的时候，尽量避免在排序情况下使用分页查询排序靠后的数据
	elastisearch的数据是分片存储的，当你排序后查询第一万条数到一万零五条的数据时，它会到每一个分片区寻找出前一万零五条的所有数据重新排序后，舍弃不需要的数据，因此性能会很低，所以不要查询页数靠后的数据
	解决办法:
		Scroll search
		GET /<index>/_search?scroll=<1m一分钟>
		{
			query:{
				match_all:{}
			},
			sort:{
				<字段>:<asc/desc>
			},
			size:<数字>
		}
		这条语句会返回一个_scroll_id;
		第二次查询
		GET /_search/scroll
		{
			//第二次查询时更新scroll的过期时间
			scroll:<1m一分钟>,
			_scroll_id:"上次查询返回的id"
		}
		这条语句的作用就是你上次查询记录一个游标，下次查询省略前面的比较直接进行了后续查询

==================================================================================================================

Mapping

查看mapping
当执行put时，数据库会根据我们插入数据的分配默认数据类型
GET /<index>/_mapping

手动创建mapping
PUT /<index>
{
	mappings:{
		properties:{
			<字段名>:{
				type:<类型>
				//如果index为false，name数据就不会创建倒排索引，如果我用match区搜索就会报错，因为他为创建倒排索引
				index:<true是创建倒排索引>,
				analyzer:<指定分析器>,
				//如果设置为false,json中，支付串"10"无法插入到integer类型中，必须是10才行
				coerce:<是否允许被强制类型转换>,
				doc_values:<true/false是创建倒排索引>,
				format:<日期格式数据的时间格式>,
				fielddata:<true是支持聚合，性能低一般不使用，一般直接创建keyword并查询>
			}
			//复杂类型
			<字段名称>:{
				type:nested
				properties:{}
			}
		},
		dynamic:<是动态添加新字段,more难为true,设置为false可以被创建但是不会添加到索引中>
	}
}
------------------------------------------------------------------------------------------------------------------
数据类型
	数字类型 long,short,integer,byte,double,float,half_float,scaled_float
	字符串类型
		keyword:
			id要使用keyword类型，效率会比数字类型高
		text:
			text会走全文检索，但是不会被倒排索引，因为他的字段比较长，但是它会被分词，走全文检索。
			所以它常被用于email的内容，产品描述。字符串会被分析成一个个[词项]，但是不会被倒排索引
	date类型:
		exact value类型
	布尔类型boolean:
	二进制类型binary:
	区间类型range:
	
	复杂类型
		Object:
			用于单个JSON对象
		Nested:
			JSON数组类型
	地理位置类型:131课节略
	特有类型:131课节略
		
搜索方式
	exact value 精确匹配
	full text 全文检索

keyword实际上是创建了两个字段一个是text一个是keyword

==================================================================================================================
聚合查询
127课节1:57
相当于sql的group by
bucket	metirc
GET /<index>/_search
{
	aggs:{
		<聚合的名字>:{
			<搜索方式terms>:{
				field:<字段名.keyword>
				
			}
		}
	}
}








倒排索引和正排索引

倒排索引为了增加查询效率
	倒排索引的优势，查找包含某个项的文档，倒排索引的key是关键词
正排索引为了增加聚合效率
	哪些项是否包含在某个文档里，正排索引的key是doc的id
	正排索引的目的就是为了聚合

倒排索引:
term:doc1 doc2 doc3
哪些doc包含了当前term关键词
正排索引
doc:term1 term2 term3
doc中包含了哪些term

索引创建时,es就会生成，保存在lucence的磁盘中，如果内存足够会缓存在cache中
不分词的field会在index-time时生成正排索引，聚合直接使用正排索引
而分词的field在创建时没有正排索引

<字段名>:{
	type:<字段类型>
	doc_value:<true是生成正排索引>
	index:<true是生成倒排索引>
}







课节125后面的filter的cache缓存没有看完2：03节点





查询的返回值
{
    "took": 328,
    "timed_out": false,//是否超时,TimeOut机制，如果用户设置了超时时间,并且在规定时间内没有查询完毕，只返回已经查询到的数据
    "_shards": {
        "total": 1,
        "successful": 1,
        "skipped": 0,
        "failed": 0
    },
    "hits": {
        "total": {
            "value": 2,
            "relation": "eq"
        },
        "max_score": 1.0,
        "hits": [
            {
                "_index": "user",
                "_type": "_doc",
                "_id": "1",
                "_score": 1.0,
                "_source": {
                    "name": "xiaoming phone",
                    "desc": "shouji zhong de zhandouji",
                    "price": 38711,
                    "tags": [
                        "xingjibi",
                        "fashao",
                        "buka"
                    ]
                }
            },
            {
                "_index": "user",
                "_type": "_doc",
                "_id": "2",
                "_score": 1.0,
                "_source": {
                    "name": "pingguo shouji",
                    "desc": "wo de shouji xiaoming",
                    "price": 3940,
                    "tags": [
                        "hutu",
                        "lulu",
                        "buka"
                    ]
                }
            }
        ]
    }
}



获取分词结构
GET /forum/_analyze
{
	"field":"<field>",
	"text":<value>
}








