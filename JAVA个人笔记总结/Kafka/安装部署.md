# JAVA环境部署

1. 安装Java环境

2. 安装java11和java开发环境工具包
   ```shell
   yum install -y java-11-openjdk java-11-openjdk-devel
   ```

# Kafka


1. 下载kafka安装包

2. tar -zxvf kafka解压

3. 修改配置文件
   ```properties
   borker.id=0 #当前kafka的唯标识
   log.dirs=/opt/data #kafka默认数据的存储位置
   zookeeper.connect=localhost:2181,localhost:2182/kafka #kafka访问的zookeeper,以及默认存储信息的目录位置
   ```

## Topi

```shell
#连接到kafka,只要能连接任意一个就可以获取整个集群中的信息
./kafka-topics.sh --bootstrap-server host:port,host2:port2,...
--creaet #创建操作
--delete #删除操作
--aleter #修改操作
--list #查看所有主题
--describe #查看主题详情描述
--partitions <int> #设置分区数
--replication-factor<int> #设置副本数
#创建topic
./kafka-topics.sh --bootstrap-server <host>:<port> --topic <topic-name> --create --partitions 1 --replication-factor 1 
```

## Producer

```shell
./kafka-console-producer.sh --bootstrap-server host:port
--topic <string> #指定被发送的主体名称

#发送消息
./kafka-console-producer.sh --bootstrap-server localhost:9092 --topic my-new-topic
> hello
```

```java
//配置信息
Properties properties = new Properties();
//连接集群
properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "47.93.102.54:9092");
//配置序列化器
properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

//创建生产者
KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties);

//发送异步消息
kafkaProducer.send(new ProducerRecord<>("my-new-topic", "hello"));
//发送同步数据,代码上末尾加上get()方法,
kafkaProducer.send(new ProducerRecord<>("my-new-topic", "hello")).get();

//关闭生产者
kafkaProducer.close();
```

- 分区器

  - 分区策略

    - 默认的分区策略

      - 发送时指定分区id,则发送到指定的分区
      - 未指定分区id,但是指定了key则按照key取模进行分区
      - 既未指定分区id也未指定key则当前分区存满后在随机选用另一个分区(和上次分区不同)

    - 自定义分区策略

      - 实现Partitioner接口

      - ```java
        //自定义分区器
        properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, MyPartitioner.class.getName());
        ```

## Consumer

```shell
./kafka-console-consumer.sh --bootstrap-server host:port
--topic <string> #指定接收的主题
--from-beginnig #是否接收之前的历史数据
```

## 流程

1. main()->send(ProducerRecord)
2. Interceptors拦截器
3. Serializer序列化器
4. Partitioner分区器
   - 用于控制数据分配到哪一个DQuene中
   - RecordAccumulator默认32M
   - batch.size生产者需要收集一定量数据后才会把数据发送给Broker,使用batch.size设置默认收集的大小
   - linger.ms如果生产者数据迟迟没有更新,则在设置指定ms后也会把数据发送,默认为0即有数据就立即发送
5. Sender线程
   1. Sender负责读取数据
   2. NetworkClient负责缓存请求
   3. Selector负责将数据发送到Broker
   4. 发送成功,就清除对应的请求和分区的数据
   5. 如果失败,就重试,直到int最大值
6. Broker接受数据
   - 模式0,生产者发送的数据不需要等数据落盘就返回成功
   - 模式1,Leader收到数据后应答
   - 模式-1(all),生产者发送过来的数据,Leader和ISR队列里的所有节点都收齐数据后应答

## 数据的重复

enable.idempotence=true # 默认是开启的

每次发送消息会携带PID和sequeue

PID每次重启会重新分配 seq单调递增

# Zookeeper


1. 安装zookeeper

2. 修改config目录下zoo_sample.cfg -> zoo.cfg

3. 修改配置文件
   ```properties
   dataDir=/temp/zookeeper #修改zookeeper文件的存储位置
   clientPort=2181 #zookeeper运行端口号
   ```

4. 启动zookeeper
   ```shell
   #进入到bin目录
   cd bin/
   #启动服务端
   ./zkServer.sh start
   #停止服务
   ./zkServer.sh stop
   #打开客户端
   ./zkCli.sh
   ```
   
   