# JAVA环境部署

1. 安装Java环境

2. 安装java11和java开发环境工具包
   ```shell
   yum install -y java-11-openjdk java-11-openjdk-devel
   ```

# Kafka


1. 下载kafka安装包

2. tar -zxvf kafka解压

3. 修改配置文件
   ```properties
   borker.id=0 #当前kafka的唯标识
   log.dirs=/opt/data #kafka默认数据的存储位置
   zookeeper.connect=localhost:2181,localhost:2182/kafka #kafka访问的zookeeper,以及默认存储信息的目录位置
   ```

 4. 启动kafka
    ```shell
    ./kafka-server-start.sh -daemon ../config/server.properties
    ```

    

## Topi

```shell
#连接到kafka,只要能连接任意一个就可以获取整个集群中的信息
./kafka-topics.sh --bootstrap-server host:port,host2:port2,...
--creaet #创建操作
--delete #删除操作
--aleter #修改操作
--list #查看所有主题
--describe #查看主题详情描述
--partitions <int> #设置分区数
--replication-factor<int> #设置副本数
#创建topic
./kafka-topics.sh --bootstrap-server <host>:<port|9092> --topic <topic-name> --create --partitions 1 --replication-factor 1 
```

## Producer

```shell
./kafka-console-producer.sh --bootstrap-server host:port
--topic <string> #指定被发送的主体名称

#发送消息
./kafka-console-producer.sh --bootstrap-server localhost:9092 --topic my-new-topic
> hello
```

```java
//配置信息
Properties properties = new Properties();
//连接集群
properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "47.93.102.54:9092");
//配置序列化器
properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

//创建生产者
KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties);

//发送异步消息
kafkaProducer.send(new ProducerRecord<>("my-new-topic", "hello"));
//发送同步数据,代码上末尾加上get()方法,
kafkaProducer.send(new ProducerRecord<>("my-new-topic", "hello")).get();

//关闭生产者
kafkaProducer.close();
```

```java
//配置文件
Properties properties = new Properties();

properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "47.93.102.54:9092");//连接集群
properties.put(ProducerConfig.ACKS_CONFIG, "all");
properties.put(ProducerConfig.RETRIES_CONFIG, "0");
properties.put(ProducerConfig.BATCH_SIZE_CONFIG, "16384");
properties.put(ProducerConfig.LINGER_MS_CONFIG, "1");
properties.put(ProducerConfig.BUFFER_MEMORY_CONFIG, "33554432");
properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());//配置序列化器
properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, "com.chp.kafka.MyPartitioner");//自定义分区器

//创建生产者
KafkaProducer<String, String> producer = new KafkaProducer<>(properties);

//发送数据
for (int i = 0; i < 10; i++) {
    producer.send(new ProducerRecord<>("my-new-topic", "1", "hello"));
}
producer.close();
```



- 分区器

  - 分区策略

    - 默认的分区策略

      - 发送时指定分区id,则发送到指定的分区
      - 未指定分区id,但是指定了key则按照key取模进行分区
      - 既未指定分区id也未指定key则当前分区存满后在随机选用另一个分区(和上次分区不同)

    - 自定义分区策略

      - 实现Partitioner接口

      - ```java
        //自定义分区器
        properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, MyPartitioner.class.getName());
        ```

## Consumer

```shell
./kafka-console-consumer.sh --bootstrap-server host:port
--topic <string> #指定接收的主题
--from-beginnig #是否接收之前的历史数据
```

```java
//配置
Properties properties = new Properties();
properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "47.93.102.54:9092");
properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
properties.put(ConsumerConfig.GROUP_ID_CONFIG, "group-01");
//创建消费者
KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);
//订阅主题
consumer.subscribe(List.of("my-new-topic"));
//消费数据
while (true) {
ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
records.forEach(record -> {
System.out.println(record);
});
```



- 消息丢列消息推送方式
  - pull拉取
  - push推送
- kafka使用的主动拉取的方式
  - 主动拉取数据的缺点,没有数据时会陷入空转
- 消费者和消费者组
  - 每一个消费者可以消费一次leader中的数据
  - 消费者组,同一个消费者组只能有一个消费者消费同一份数据
    - 所有的消费者都会配置一个groupid,如果groupid相同,就会自动形成一个消费者组
    - 消费者组内每一个消费者负责消费不同分区数据,一个分区只能由一个组内消费者消费
    - 如果分区的数量大于消费者的数量就会有消费者无法消费,进入闲置

## 流程

1. main()->send(ProducerRecord)
2. Interceptors拦截器
3. Serializer序列化器
4. Partitioner分区器
   - 用于控制数据分配到哪一个DQuene中
   - RecordAccumulator默认32M
   - batch.size生产者需要收集一定量数据后才会把数据发送给Broker,使用batch.size设置默认收集的大小
   - linger.ms如果生产者数据迟迟没有更新,则在设置指定ms后也会把数据发送,默认为0即有数据就立即发送
5. Sender线程
   1. Sender负责读取数据
   2. NetworkClient负责缓存请求
   3. Selector负责将数据发送到Broker
   4. 发送成功,就清除对应的请求和分区的数据
   5. 如果失败,就重试,直到int最大值
6. Broker接受数据
   - 模式0,生产者发送的数据不需要等数据落盘就返回成功
   - 模式1,Leader收到数据后应答
   - 模式-1(all),生产者发送过来的数据,Leader和ISR队列里的所有节点都收齐数据后应答

## 数据的重复

enable.idempotence=true # 默认是开启的

每次发送消息会携带PID和sequeue

PID每次重启会重新分配 seq单调递增

# Zookeeper


1. 安装zookeeper

2. 修改config目录下zoo_sample.cfg -> zoo.cfg

3. 修改配置文件
   ```properties
   dataDir=/temp/zookeeper #修改zookeeper文件的存储位置
   clientPort=2181 #zookeeper运行端口号
   ```

4. 启动zookeeper
   ```shell
   #进入到bin目录
   cd bin/
   #启动服务端
   ./zkServer.sh start
   #停止服务
   ./zkServer.sh stop
   #打开客户端
   ./zkCli.sh
   ```
   
   