无法量化
图像RGB(0~255,0~255,0~255)
灰度图，将三种颜色加权求和，3byte转化为1byte的，彩色图转化为黑白图片
不同图片的大小不同，为了将图片大小统一要进行图片缩放

文章向量化
acd可以用一下方式表示该文章
abcdefg
1011000
弊端,用来表示依据化会出现大量的0位;没有考虑词的顺序;会出现歧义，苹果手机和吃的苹果 one-hot向量法

男女向量化[0,1]男[1,0]女;为了让男女不具有大小关系，而不用0男1女

颜色也没有大小的概念，所以颜色的数据也不应该出现大小的区别，颜色向量也要用[0,1,0,0,0,]来表示



人工智能中，某些模型分析时，应该避免平级状态用有大小分别的数据表示

将业务场景的东西变成多维数组的模型，基于多维数组的模型进行分析，就可以抛开原有的业务场景作分析
提取特征的过程叫做特征工程



深度学习模型
降低了特征提取的难度，提升了模型处理难度


模拟神经元的函数,数字在很小或很大时对变化都是弱敏感
sigmoid函数
1/1+e^-2

泰勒展开式



简单线性回归
集中趋势衡量
	均值(平均数，平均值)
	中位数
	众数
离散程度衡量
	方差：s^2 = (每个数-平均数)^2/(数的个数-1)
	标准差：方差的开方 = s
简单线性回归
	回归和分类的概念
		回归：Y因变量为连续值型，如：房价，降雨量
		分类：Y因变量为类别型，如：颜色
	回归分析：
		建立方程，模拟两个或者多个变量是如何关联的
		被预测的变量，叫做因变量
		用于进行预测的变量，自变量
	如果我们的自变量包含两个或两个以上，我们称之为多元回归分析
	
	简单线性回归的模型
		y = β0 + β1x + ε
		y因变量，x自变量，ε是偏差，β0、β1是参数
		
	线性回归方程
		E(y) = β0 + β1x
		β0就是截距，β1就是斜率，E(y)就是期望、均值
	正向线性相关，负向线性相关，无关系
	y头上带有-代表平均值
	y头上带有^代表估计值
	y前面有一个E,均值
	
	ε服从正态分布，均值是0
	
	min∑(yi-(^yi))^2

	
	b0 = _y -b1_x
	
	b1 = ∑(xi-_x)(yi-_y)/∑(xi-_x)^2
	b0 = _y -b0_x
	
	多元线性回归
	整体的期望值的和等于每一项期望值的求和
	E(y) = β0 + β1x1 + β2x2 + β3x3 + β4x4 + β5x5 + ... + βpxp
	
	
因式分解
	提公因式
	平法差公式
	完全平方公式
	十字相乘法

机械学习的类型
	有监督学习，训练集有类别的标记
	无监督学习，无类别标记
	半监督学习，有类别标记的训练集+无标记的训练集

机械学习中分类和预测评估
准确率
速度
强壮性：数据有噪音时，算法是否仍能表现的很好
可规模性：当数据非常大时，是否会出现问题
可解释性：算法提供出分类后，是否能很好解释依据


决策树归纳算法
	信息熵：
		信息是抽象的概念，一条信息的信息量大小和他的不确定性有直接关系，我们对一件事一无所知，我们就需要大量信息==>信息量的度量就等于不确定性的多少
		p代表夺冠率
		-(p1 * log p1 + p2 * log p2 + ...)
		P(X)是每一个情况可发生的概率
		H(X) = - ∑ P(x)log2 [P(x)]

	根据每条信息熵的大小进行排序，信息熵大的信息作为决策树的上层节点
	
	ID3
		根据信息熵选择节点属性
		属性必须是分类及离散值，如果不是，则需要通过划分范围的方式离散化
		当给定的样本都属于同一类，就进行停止
		样本用完了，就采用多数表决，及他的样本哪类最多就选用哪类
	
	优点，直观便于理解，小规模数据有效
	缺点，连续性不好，类别多时错误增加比较快，可规模性一般
	
	@@决策树的总结，就是通过采集样本，给定多个条件，通过信息熵比较了解那个信息更有价值，在通过样本列出树状图，在给定条件下发生的概率是否是100%，不是就给出第二个条件，直到100%或者样本用完后采取少数服从多数

	格式转化age分为 youth middle senior ，一个人属于youth 那他的数据就是 youth:1,middle:0,senior:0这样的写法
	
	



KNN算法
	分类算法，根据特征值进行分类


模型:{
	分类:{
		二分类:输出结果是boolean
		多分类:输出结构是一个enum
	},
	回归:{
		实数集:输出结果是一个范围range
	},
	聚类:我们不知道要分几种,机械自己分
}

假设空间:{
	归纳,演绎
}

模型评估和选择:


数据集:
	训练集:机械训练使用的数据
	验证集:手动调参过程中用于验证参数准确性的训练数据
	测试集:最终验证数据准确性的数据


线性模型:{
	n元1次方程
	f(x) = w_1*x_1 + w_2 * x_2 + ...  + w_d * x_d + b
	矩阵相乘:{
		a*b
		行*列
		a列数 必须等于 b列数
		列数:m
		行数:d
		m*d的矩阵
	}
}


a_11 * x_1 + a_12 * x_2 = b_1
a_21 * x_1 + a_22 * x_2 = b_2

|a_11, a_12|  = a_11 * a_22 - a_12 * a_21
|a_21, a_22|

全排列: n!
逆序:当两个元素的先后顺序与标准次序不同时,就称这两个元素组成一个逆序(两个元素只要都在一个排序里,但不一定相邻)
逆序数:排列中所有逆序的总数称为逆序数
奇排列:逆序数为奇数的排列
偶排列:逆序数为偶数的排序
t(32514)  = 0 + 1 + 0 + 3 + 1 = 5
n阶行列式:
	- n阶行列式共有n!项
	- 每一项都是不同行不同列的n个元素的乘积
	- 每一项都可以写成a_1p__1 * a_2p__2 * a_3p__3 * ... * a_np__n,其中p_1,p_1,p_3, ... , p_n是1,2,3, ... ,n的某个排列
	- 当p1p2p3是偶排列时,对应项取正号
	- 当p1p2p3是奇排列时,对应项取负号
对换:
	在排列中,将任意两个元素对调,其余元素不动,这种做出新排列的手续叫做 对换

	将相邻两个元素对换,叫做 相邻对换

不相邻对换可以转化为2m+1次相邻对换,以此来简化问题

对换会改变排列的奇偶性







