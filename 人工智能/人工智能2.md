## 特征工程

- 特征提取
- 特征预处理: 通过一些函数转换数据转成更加适合算法模型的特征数据过程
- 特征降为: 指在某种限定条件下, 降低随机变量(特征)个数, 得到一组"不相关"主变量的过程

## 机械学习

选择合适的算法对模型进行训练

## 模型评估

## 机械学习

- 机械学习的分类
  - 监督学习
    - 输入的数据是由输入特征值和目标值所组成
    - 监督学习的分类
      - 回归: 函数的输出可以是一个连续的值
      - 分类: 输出值是有限个离散的
  - 无监督学习
    - 输入数据是由特征值构成, 没有目标值
  - 半监督学习
  - 强化学习

> 监督学习和无监督学习的对比
>
> ​	监督学习: 输入数据有特征有标签, 及有标准答案
>
> ​	无监督学习: 输入数据有特征无标签, 及无标准答案



概念:

> 要进行机器学习，先要有数据.假定我们收集了一批关于西瓜的数据，例 如(色泽=青绿;根蒂=蜷缩;敲声=浊响)， (色泽=乌黑;根蒂:稍蜷;敲声=沉 闷)， (色泽=浅自;根蒂 硬挺;敲声=清脆)，……，每对括号内是一条记录， "="意思是"取值为"

- 这组记录的集合称为一个"数据集" (data set)

- 其中每条记录是关于一 个事件或对象(这里是一个西瓜)的描述，称为一个"示例" (instance) 或"样 本" (samp1e).

- 反映事件或对象在某方面的表现或性质的事项，例如"色泽" "根蒂" "敲声"，称为")副主" (attribute) 或"特征" (feature);

- 属性上的取值，例如"青绿" "乌黑"，称为"属性值" (attribute value).

- 属性张成的空间称为"属性空间" (attribute space) "样本空间" (sample space) 或"输入空间"

  > 例如我们把"色泽" "根蒂" "敲声"作为三个坐标轴，则它们张成 一个用于描述西瓜的三维空间，每个西瓜都可在这个空间中找到自己的坐标位置.由于空间中的每个点对应一个坐标向量，因此我们也一个示例称为一个 "特征向量" (feature vector). 

$$
D={x_1,x_2,\cdots,x_3}表示包含m个事例的数据集,每个事例由d个属性描述(例如上面的西瓜使用了三个属性)\\
则每个事例x_i=(x_{i1};x_{i2};\cdots;x_{id})是d维样本空间X中的一个向量,x_i\in X \\
其中x_{ij}是x_i在第j个属性上的取值,d称为x_i的"维数"(dimensionality)
$$

- 从数据中学得模型的过程称为"学习" (learning) 或"训练" (training),  这个过程通过执行某个学习算法来完成
- 训练过程中使用的数据称为"训练数据" (training data)
- 其中每个样本称为一个"训练样本" (training sample)
- 学得模型对应了关于数据的某种潜在的规律，因此亦称"假设" (hypothesis)
- 这种潜在规律自身，则称 为"真相"或"真实" (ground-truth)
- 学习过程就是为了找出或逼近真相.本 书有时将模型称为"学习器" (learner) ，可看作学习算法在给定数据和参数空间上的实例化.
- 如果希望学得一个能帮助我们判断没剖开的是不是"好瓜"的模型，仅 有前面的示例数据显然是不够的要建立这样的关于"预测" (prediction) 模型
- 我们需获得训练样本的"结果"信息，例如" ((色泽:青绿;根蒂二蜷缩; 敲声=浊响)，好瓜)" .这里关于示例结果的信息，例如"好瓜"，称为"标 记" (label);
- 拥有了标记信息的示例，则称为"样例" (example).
-  一般地，用$(x_i,y_i)$ 表示第 个样例 其中 $y_i\in Y$ 是示例$x_i$的标记,$Y$是所有标记的集合，亦称"标记空间" (label space)或"输出空间
- 若我们欲预测的是离散值，例如"好瓜" "坏瓜"，此类学习任务称为 "分类" (classification);
- 若欲预测的是连续值?例如西瓜成熟度 0.95 0.37 此类学习任务称为"回归" (regression)
- 对只涉及两个类别的"二分 类" (binary classification) 任务，通常称其中一个类为 正类" (positive class) 另一个类为"反类" (negative class); 
- 涉及多个类别时，则称为"多分类"(multi-class classification)任务