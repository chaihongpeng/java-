## K近邻算法(KNN)

- 欧氏距离
  - $二维距离公式:d_{12}=\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}$ 
  - $n维距离公式:d_{12}=\sqrt{\sum\limits^n_{k1}(x_{1k}-x_{2k})^2}$ 
- k近邻算法属于监督学习算法,kmeans是无监督学习算法
- k近邻算法的弊端, 它在识别图像时无法区分主体成分和背景, 因此k近邻会把背景相似或形状相似的图片划分为同一类别

## 常用的聚类算法

- Meanshift均值漂移聚类
  - 算法流程
    - 在中心点一定区域内检索数据
    - 更新中心点
    - 重复流程到中心点稳定
  - 特点
    - 自动发现类别数量,不需要人工选择
    - 需要选择区域半径
- DBSCAN算法

### K均值算法

- 以空间中k个点为中心进行聚类,对最靠近他们的对象进行归类,是聚类算法中最为基础但也最为重要的算法

## 主成分分析

- PCA:数据姜维技术中,应用最多的方法

  - 寻找k(k<n)维新数据,使他反映事务的主要特征
  - 核心:在信息损失尽可能少的情况下,降低数据损失

- 主成分分析实质:

  - 3D到2D:在空间中建立一个平面,使所有点到平面的距离尽可能的小,点到平面的距离实际上就是损失的信息
  - 主成分分析就是建立一个更低维度的空间,让所有的元素都投影在这个低维空间上

  - 高纬度数据中,不同维度数据之间是具有很高的相关性,主成分分析的目的是将投影之后不同特征的数据尽可能分开,让维度间减少相关性

# 深度学习

## 多层感知器

# 损失函数

$L_i=\sum_{j\neq y}\max(0,s_j-s_{y_j}+\Delta)$

$s_j$是正确类别的得分

$s_{y_j}$是第$i$个错误类别的得分

$\Delta$代表容忍程度, 正确结果必须要比错误结果高出$\Delta$个数值才被认为能够区分出数据
