
# 名词

- record(记录):每一个样本
- feature(特征):样本的每一列, 数据库里叫做字段

## K近邻算法(KNN)

- 欧氏距离
  - $二维距离公式:d_{12}=\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}$ 
  - $n维距离公式:d_{12}=\sqrt{\sum\limits^n_{k1}(x_{1k}-x_{2k})^2}$ 
- k近邻算法属于监督学习算法,kmeans是无监督学习算法
- k近邻算法的弊端, 它在识别图像时无法区分主体成分和背景, 因此k近邻会把背景相似或形状相似的图片划分为同一类别

## 常用的聚类算法

- Meanshift均值漂移聚类
  - 算法流程
    - 在中心点一定区域内检索数据
    - 更新中心点
    - 重复流程到中心点稳定
  - 特点
    - 自动发现类别数量,不需要人工选择
    - 需要选择区域半径
- DBSCAN算法

### K均值算法

- 以空间中k个点为中心进行聚类,对最靠近他们的对象进行归类,是聚类算法中最为基础但也最为重要的算法

## 主成分分析

- PCA:数据姜维技术中,应用最多的方法

  - 寻找k(k<n)维新数据,使他反映事务的主要特征
  - 核心:在信息损失尽可能少的情况下,降低数据损失

- 主成分分析实质:

  - 3D到2D:在空间中建立一个平面,使所有点到平面的距离尽可能的小,点到平面的距离实际上就是损失的信息
  - 主成分分析就是建立一个更低维度的空间,让所有的元素都投影在这个低维空间上

  - 高纬度数据中,不同维度数据之间是具有很高的相关性,主成分分析的目的是将投影之后不同特征的数据尽可能分开,让维度间减少相关性

# 深度学习

## 多层感知器

# 损失函数

$L_i=\sum_{j\neq y}\max(0,s_j-s_{y_j}+\Delta)$

$s_j$是正确类别的得分

$s_{y_j}$是第$i$个错误类别的得分

$\Delta$代表容忍程度, 正确结果必须要比错误结果高出$\Delta$个数值才被认为能够区分出数据



## 梯度下降

局部最优问题并不是很常见, 鞍点问题更为常见, 斜率为0,多维向量像一个马鞍一样,从不同维度的斜率出现完全相反的结果

# 激活函数

$$
softmax(x)_i=\dfrac{\exp(x_i)}{\sum_j{\exp(x_j)}}
$$

- $\exp(x)$就是以自然数$e$为底,$x$次方的指数函数
- $e$就是近似等于$2.718281828$常数,还成为欧拉数

## Logistic

$$
logistic(x)=\dfrac{1}{1+e^{-x}}
$$



# 代价函数

## 二次代价函数

$$
E=\dfrac{1}{2}(t-y)^2
$$

## 交叉熵

$$
E=-(t\ln{y}+(1-t)\ln{(1-y)})
$$

- $t$代表正确标签,$y$表示预测值

熵: 一个体系里的混乱程度

信息: 对不确定性的消除

> $$
> f(x):=信息量\\
> f(阿根廷夺冠) = f(阿根廷进入决赛)+f(阿根廷赢得决赛)\\
> f(阿根廷进入决赛 * 阿根廷赢得决赛) = f(阿根廷进入决赛)+f(阿根廷赢得决赛)\\
> f(x_1 * x_2) = f(x_1)+f(x_2)\\
> f(x):=-\log_2{x}\\
> 事件发生时,发生此事件的概率越小,信息量越大
> 概率模型事例: 世界杯P(阿根廷夺冠)=P(阿根廷进入决赛) * P(阿根廷赢得决赛)\\
> $$

## KL散度(相对熵)

# 卷积神经网络(Convolutional Neuron Network/ CNN)

$$
\begin{equation}
\begin{split}
f(x)&=(ax_i+b-y_i)^2\\
f^{\prime}_a(x)&=2(ax_i+b-y_i)x_i\\
&=2ax_i^2+2x_ib-2x_iy_i
\end{split}
\end{equation}
$$

$$
\begin{equation}
\begin{split}
f(x)&=(ax_i+b-y_i)^2\\
f^{\prime}_b(x)&=2(ax_i+b-y_i)\\
&=2ax_i+b-y_i
\end{split}
\end{equation}
$$

# 线性层/全连接层(Fully Connected)

## GCN

## Convolution(卷积层)

- 一个系统有不稳定的输入, 但是有稳定的输出
- 周围像素点对当前像素点产生怎样的影响
- 过滤器,一个像素点如何试探周围的像素点,如何筛选图像的特征

$$
\int^{\infty}_{-\infty}f(\tau)g(x-\tau)d\tau
$$

## Neuron(神经元)

## Receptive Field(感受野)

## Pattern

## Chanel(通道)

## Stride(步距)

感受野每次移动的范围

## Padding

如果感受野按照步距移动到末尾, 所剩宽度不够一个感受野,则在末尾补零

## Featrure Map

特征映射, 样本经过感受野映射后产生新的结果数据

input(chanel,width,height)

# 傅里叶

- 时域
- 频域

使用果汁原料桶举例, 一分钟放一块冰糖,两分钟放一粒红豆,时间就表示的叫做时域

每隔一分钟放一块冰糖, 用频率来表示的叫做频域

- 相位: 不是同时开始的一组余弦曲线, 在叠加时要体现开始的时间

任何连续周期信号, 都可以由一组适当的正弦曲线组合而成

傅里叶变换是可逆的

傅里叶变换本质是从时域的角度去看一个函数转化为从频率的角度去看信号, 同样从频率的角度能够推回从时间的角度看信号

## 傅里叶级数

任何一个周期性函数, 都可以进行变换为一系列正余弦函数的和
$$
\begin{equation}
\begin{split}
f(t)&=\dfrac{a_0}{2}+\sum_{n=1}^{\infty}{a_n\sin(n\omega{t}+ \phi_n)}\\
    &=\dfrac{a_0}{2}+\sum_{n=1}^{\infty}(a_n\cos{nx} + b_n\sin{nx})
\end{split}
\end{equation}
$$

## 连续傅里叶变换

