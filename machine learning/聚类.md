无监督学习, 训练样本标记信息是未知的, 目标是通过对无标记训练样本的学习来揭示数据内在性质和规律, 为进一步的数据分析提供基础. 

聚类, 试图将数据集中的样本划分为若干个通常为不相交的子集, 每个子集成为一个"簇"(cluster)

聚类既能作为一个单独过程, 用于找寻数据内在的分布结构, 也可以作为分类等其他学习任务的前驱过程. 例如一些商家需要对新用户的类型进行判别, 但定义用户类型对商家不太容易, 往往可以通过先对用户进行聚类

## 性能度量(性能指标)

聚类性能的分类:

一类是将聚类结果与参考模型进行比较, 称为"外部指标"

另一类直接考察聚类结果, 而不利用任何参考模型, 称为"内部指标"

## 距离计算

我们常将属性划分为连续属性和离散属性, 在讨论距离时, 属性上是否定义了"序"关系更为重要

函数$dist(.,.)$, 若它是一个"距离度量", 则需满足一些基本性质:

- 非负性: $dist(x_i,x_j)\ge 0$
- 同一性: $dist(x_i,x_j)=0$, 当且仅当$x_i=x_j$
- 对称性: $dist(x_i,x_j)=dist(x_j,x_i)$
- 直递性: $dist(x_i,x_j)\le dist(x_i,x_k)+ dist(x_k,x_j)$

给定样本$x_i=(x_{i1};x_{i2};\cdots;x_{in})$与$x_j=(x_{j1};x_{j2};\cdots;x_{jn})$

闵可夫斯基距离:$dist_{mk}(x_i,x_j)=(\sum\limits^n_{u=1}|x_{iu}-x_{ju}|^p)^{\frac{1}{p}}\quad p\ge 1$

闵可夫斯基距离适用于有序属性

对于无序属性可采用VDM(Value Difference Metric). 令$m_{u,a}$表示属性$u$上的取值为$a$的样本个数, $m_{u,a,i}$表示在第$i$个样本簇中与属性$u$上的取值为$a$的样本簇, 则属性$u$上的两个离散值$a$和$b$之间的VDM距离为
$$
VDM_p(a,b)=\sum\limits^k_{i=1}|\dfrac{m_{u,a,i}}{m_{u,a}}-\dfrac{m_{u,b,i}}{m_{u,b}}|^p
$$
