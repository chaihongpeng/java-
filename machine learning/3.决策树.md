## 决策树

信息熵 $Ent(D)=-\sum\limits_{k=1}^{|Y|}p_k\log_2p_k$

## 决策树

- 决策树构建
  - 利用信息熵原理选择信息熵最大的属性作为分类属性,递归拓展决策树的分支,完成决策树的构造

- 信息熵
  - 度量随机变量不确定性的指标,熵越大,变量的不确定性就越大
  - $假定当前样本集合D中第k类样本所占的比例为p_k,则D的信息熵为:$
    $Ent(D)=-\sum\limits^{|y|}_{k=1}p_k\log_2p_k$ 
  - $Ent(D)的值越小,变量的不确定性越小$ 